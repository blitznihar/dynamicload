{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Create a dropdown widget for environment selection\n",
    "interface_dropdown = widgets.Dropdown(\n",
    "    options=[\"LAWSON-0005\", \"LAWSON-0006\", \"LAWSON-0007\"],\n",
    "    value=\"LAWSON-0006\",\n",
    "    description=\"Interface:\",\n",
    ")\n",
    "\n",
    "# Display the widget\n",
    "# display(widgets.HBox([interface_dropdown, outputdirectory]))\n",
    "display(widgets.HBox([interface_dropdown]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Configuration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "# Database connection parameters\n",
    "db_user = 'root'\n",
    "db_password = 'strong_password'\n",
    "db_host = 'localhost'\n",
    "db_name = 'yourdb'\n",
    "db_port = 33062\n",
    "interface_id = interface_dropdown.value\n",
    "\n",
    "# Create a database connection\n",
    "engine = create_engine(f'mysql+pymysql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "\n",
    "# Query to read data for a specific interfaceID\n",
    "queryInterface = f\"SELECT * FROM interface WHERE interfaceID = '{interface_id}'\"\n",
    "\n",
    "# Load data into dataframe\n",
    "dfInterface = pd.read_sql(queryInterface, engine)\n",
    "\n",
    "mappingId = dfInterface['MappingID'].astype(str).to_string(index=False)\n",
    "\n",
    "# Query to read data for a specific interfaceID\n",
    "queryMapping = f\"SELECT * FROM mapping WHERE mappingID = '{mappingId}'\"\n",
    "\n",
    "# Load data into dataframe\n",
    "dfMapping = pd.read_sql(queryMapping, engine)\n",
    "\n",
    "display(dfInterface)\n",
    "display(dfMapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Fixed Length File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#LOGIC FOR FIXED WIDTH FILE\n",
    "if(dfInterface['SourceType'].head(1).to_string(index=False).upper()):\n",
    "    colspecs = [(row['Start'], row['Start'] + row['SourceLength']) for index, row in dfMapping.iterrows() if row['SourceField'] is not None]\n",
    "    names = [row['SourceField'] for index, row in dfMapping.iterrows() if row['SourceField'] is not None]  # Column names\n",
    "    dfSource = pd.read_fwf('SourceFileFixedWidth.dat', colspecs=colspecs, names=names, header=None)\n",
    "\n",
    "#LOGIC FOR DELIMITED FILE\n",
    "elif(dfInterface['SourceType'].to_string(index=False).upper() == 'DELIMITED'):\n",
    "    delimiter = dfMapping['SourceDelimiter'].to_string(index=False)\n",
    "    names = [row['SourceField'] for index, row in dfMapping.iterrows() if row['SourceField'] is not None]  # Column names\n",
    "    dfSource = pd.read_csv('Delimited.dat', delimiter=delimiter, names=names, header=None)\n",
    "#dfSource = pd.read_csv('SourceFileDelimited.dat', delimiter='|', names=names, header=None)\n",
    "\n",
    "print(dfSource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map to Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame with the same columns as dfSource\n",
    "dfDestination = pd.DataFrame(columns=dfSource.columns)\n",
    "#Solidify the Mapping logic and data transformation\n",
    "    \n",
    "\n",
    "destinationFields = ''\n",
    "for index, row in dfMapping.iterrows():\n",
    "    destination = row['Destination']\n",
    "    source = row['SourceField']\n",
    "    mapping_function = row['MappingFunction']\n",
    "    destination_type = row['DestinationType']\n",
    "    if mapping_function == 'PASSTHROUGH':\n",
    "        if index == len(dfMapping) - 1:\n",
    "            destinationFields += destination\n",
    "        else:\n",
    "            destinationFields += destination + ','\n",
    "    else:\n",
    "        if index == len(dfMapping) - 1:\n",
    "            destinationFields += f'{mapping_function} AS {destination}'\n",
    "        else:\n",
    "            destinationFields += f'{mapping_function} AS {destination},'\n",
    "\n",
    "destinationQuery = f\"SELECT {destinationFields} FROM dfSource\"\n",
    "print(destinationQuery)\n",
    "print(destinationFields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandasql as psql\n",
    "\n",
    "dfDestination = psql.sqldf(destinationQuery, globals())\n",
    "\n",
    "print(dfDestination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load into Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the destination table name from the interface table\n",
    "destination_table = dfInterface['DestinationType'].iloc[0]\n",
    "print(destination_table)\n",
    "# Load the dataframe into the SQL table\n",
    "dfDestination.to_sql(destination_table, engine, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"Data loaded into table {destination_table} successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
